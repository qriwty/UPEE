
## Стохастичний експеримент. Простір елементарних подій. Операції над подіями. Комбінаторна та геометрична ймовірності. Умовна ймовірність

### Стохастичний експеримент

**Стохастичний експеримент** - це експеримент, результат якого не можна передбачити з повною впевненістю.

### Простір елементарних подій

**Простір елементарних подій** - це множина всіх можливих результатів стохастичного експерименту, позначається $S$.

### Операції над подіями

- **Об’єднання подій (Union)**: подія, що відбувається, якщо відбувається принаймні одна з подій $A$ або $B$.

$$
A \cup B
$$

- **Перетин подій (Intersection)**: подія, що відбувається, якщо відбуваються обидві події $A$ і $B$.

$$
A \cap B
$$

- **Різниця подій (Difference)**: подія, що відбувається, якщо відбувається подія $A$, але не відбувається подія $B$.

$$
A - B
$$

- **Доповнення події (Complement)**: подія, що відбувається, якщо подія $A$ не відбувається.

$$
\overline{A}
$$

### Комбінаторна ймовірність

**Комбінаторна ймовірність** - це ймовірність події, визначена через кількість сприятливих випадків і загальну кількість можливих випадків.

$$
P(A) = \frac{\text{кількість сприятливих випадків}}{\text{загальна кількість випадків}}
$$

### Геометрична ймовірність

**Геометрична ймовірність** - це ймовірність події, що визначається через відношення геометричних мір.

$$
P(A) = \frac{\text{мірна величина сприятливої області}}{\text{мірна величина всього простору}}
$$

### Умовна ймовірність

**Умовна ймовірність** події $A$ при умові, що подія $B$ відбулася:

$$
P(A|B) = \frac{P(A \cap B)}{P(B)}
$$

## Формула повної ймовірності. Формула Байєса. Схема незалежних випробувань Бернуллі. Закон великих чисел

### Формула повної ймовірності

**Формула повної ймовірності** використовується для обчислення ймовірності події $A$, розглядаючи всі можливі події $B_i$:

$$
P(A) = \sum_{i} P(A|B_i) P(B_i)
$$

### Формула Байєса

**Формула Байєса** дозволяє обчислити умовну ймовірність події $A$ при умові, що відбулася подія $B$:

$$
P(A|B) = \frac{P(B|A) P(A)}{P(B)}
$$

### Схема незалежних випробувань Бернуллі

**Схема Бернуллі** - це набір незалежних випробувань, кожне з яких має два можливих результати: успіх (з ймовірністю $p$) або невдача (з ймовірністю $1-p$).

### Закон великих чисел

**Закон великих чисел** стверджує, що середнє значення результатів великої кількості незалежних випробувань буде наближатися до математичного сподівання.

$$
\overline{X}_n \to \mu \text{ при } n \to \infty
$$

## Числові характеристики одновимірних випадкових величин (математичне сподівання, середнє значення, медіана та дисперсія)

### Математичне сподівання

**Математичне сподівання** випадкової величини $X$ - це середнє значення, якого можна очікувати в довгостроковій перспективі:

$$
E(X) = \sum_{i} x_i P(x_i)
$$

### Середнє значення

**Середнє значення** - це сума всіх значень, поділена на їх кількість:

$$
\overline{X} = \frac{1}{n} \sum_{i=1}^{n} x_i
$$

### Медіана

**Медіана** - це значення, яке розділяє вибірку на дві рівні частини.

### Дисперсія

**Дисперсія** - це міра розсіювання випадкової величини навколо її математичного сподівання:

$$
Var(X) = E[(X - E(X))^2]
$$

## Поняття розподілу випадкової величини. Функція розподілу. Щільність розподілу. Рівномірний та нормальний розподіли

### Поняття розподілу випадкової величини

**Розподіл випадкової величини** описує ймовірності, з якими випадкова величина приймає ті чи інші значення.

### Функція розподілу

**Функція розподілу** $F(x)$ визначає ймовірність того, що випадкова величина $X$ прийме значення, менше або рівне $x$:

$$
F(x) = P(X \le x)
$$

### Щільність розподілу

**Щільність розподілу** $f(x)$ визначає ймовірність того, що випадкова величина прийме певне значення:

$$
P(a \le X \le b) = \int_{a}^{b} f(x) \, dx
$$

### Рівномірний розподіл

**Рівномірний розподіл** - це розподіл, де всі значення в певному інтервалі мають однакову ймовірність.

### Нормальний розподіл

**Нормальний розподіл** - це розподіл, що має форму дзвона, симетричний щодо середнього значення. Він визначається середнім $\mu$ і стандартним відхиленням $\sigma$:

$$
f(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$

## Поняття статистичного зв'язку. Лінійна і логічна регресія. Коефіцієнт парної кореляції

### Поняття статистичного зв'язку

**Статистичний зв'язок** - це залежність між двома або більше випадковими величинами.

### Лінійна регресія

**Лінійна регресія** використовується для моделювання лінійної залежності між двома змінними:

$$
y = a + bx
$$

### Логічна регресія

**Логічна регресія** використовується для моделювання залежності, де результатом є бінарна змінна.

### Коефіцієнт парної кореляції

**Коефіцієнт парної кореляції** $r$ визначає силу і напрямок лінійного зв'язку між двома змінними:

$$
r = \frac{\sum (x_i - \overline{x})(y_i - \overline{y})}{\sqrt{\sum (x_i - \overline{x})^2 \sum (y_i - \overline{y})^2}}
$$

## Багатовимірні дискретні величини. Поняття про сумісний розподіл. Кореляційна матриця

### Багатовимірні дискретні величини

**Багатовимірні дискретні величини** - це випадкові величини, що мають дискретний розподіл у багатовимірному просторі.

### Сумісний розподіл

**Сумісний розподіл** визначає ймовірності для всіх можливих значень двох або більше випадкових величин.

### Кореляційна матриця

**Кореляційна матриця** - це матриця, що показує кореляцію між всіма можливими парами випадкових величин у наборі даних.

## Поняття випадкової функції та випадкового процесу

### Випадкова функція

**Випадкова функція** - це функція, яка залежить від випадкової величини.

### Випадковий процес

**Випадковий процес** - це сім'я випадкових величин, індексованих за часом або простором.

## Основні задачі математичної статистики. Первинна обробка даних

### Основні задачі математичної статистики

- Оцінювання параметрів розподілу
- Перевірка статистичних гіпотез
- Аналіз залежностей між змінними

### Первинна обробка даних

**Первинна обробка даних** включає очищення даних, обчислення основних статистик, візуалізацію та підготовку даних для подальшого аналізу.

## Візуалізація даних (точкова діаграма, гістограма, стовпчата діаграма, кругова діаграма)

### Точкова діаграма

**Точкова діаграма** використовується для відображення взаємозв'язку між двома змінними у вигляді точок на координатній площині.

### Гістограма

**Гістограма** використовується для відображення розподілу числових даних, показуючи частоту появи значень у вигляді стовпців.

### Стовпчата діаграма

**Стовпчата діаграма** використовується для порівняння категорій, показуючи значення у вигляді вертикальних або горизонтальних стовпців.

### Кругова діаграма

**Кругова діаграма** використовується для відображення пропорцій частин до цілого у вигляді сегментів кола.

## Точкові та інтервальні оцінки характеристик випадкових величин. Довірчі інтервали

### Точкові оцінки

**Точкова оцінка** - це одинична оцінка параметра розподілу, обчислена на основі вибірки.

### Інтервальні оцінки

**Інтервальна оцінка** - це інтервал, що містить параметр з певною ймовірністю, визначеною рівнем довіри.

### Довірчі інтервали

**Довірчий інтервал** - це інтервал, у якому з певною ймовірністю знаходиться істинне значення параметра:

$$
\overline{X} \pm z \frac{\sigma}{\sqrt{n}}
$$

## Основні поняття та перевірка статистичних гіпотез (нульова гіпотеза, альтернативна гіпотеза, рівень значущості, однорідність нормально розподілених вибірок)

### Основні поняття

- **Нульова гіпотеза (H0)**: передбачає відсутність ефекту або зв'язку.
- **Альтернативна гіпотеза (H1)**: передбачає наявність ефекту або зв'язку.

### Перевірка статистичних гіпотез

Перевірка гіпотез включає обчислення статистики тесту і порівняння її з критичним значенням для визначення, чи можна відхилити нульову гіпотезу.

### Рівень значущості

**Рівень значущості** ($\alpha$) - це ймовірність відхилення нульової гіпотези, коли вона вірна.

### Однорідність нормально розподілених вибірок

Перевірка однорідності включає порівняння вибірок для визначення, чи походять вони з одного і того ж розподілу.